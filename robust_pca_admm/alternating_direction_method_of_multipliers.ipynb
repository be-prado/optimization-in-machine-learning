{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Principal Component Analysis using the Alternating Direction Method of Multipliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pdb import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soft Threshold function\n",
    "def soft(z, lam):     \n",
    "    return np.sign(z)*np.maximum(np.abs(z)-lam,0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADMM approach solving the Robust PCA problem: \n",
    "\n",
    "\\begin{align*}\n",
    "    \\min_{\\mathbf L,\\;\\mathbf S}\\; \\| \\mathbf L \\|_* \\;+\\;\\lambda \\cdot \\|\\mathbf S\\|_1, \\quad\\text{s.t.}\\quad \\mathbf Y\\;=\\;\\mathbf L\\;+\\; \\mathbf S,\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notation here is based on notes from Boyd etal, you may see chapter 3 of https://stanford.edu/~boyd/papers/pdf/admm_distr_stats.pdf for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADMM Implementation of Robust PCA\n",
    "def ADMM(L, S, X, lam, rho, niter=10):\n",
    "    '''\n",
    "    Input: \n",
    "        L:     Low Rank Component of the Data Matrix \n",
    "        S:     The Sparse Component of the Data Matrix\n",
    "        X:     The Data Matrix\n",
    "        lam:   The regularization term \n",
    "        rho:   Augmented Lagrangian Parameter \n",
    "        niter: Number of Iterations \n",
    "        \n",
    "    Intermediate: \n",
    "        W:     The scaled Dual variables\n",
    "\n",
    "\n",
    "    Output: \n",
    "        L:     The Low Rank Component of the Data Matrix \n",
    "    '''  \n",
    "\n",
    "    W = np.zeros(L.shape)\n",
    "    \n",
    "    out = []\n",
    "    \n",
    "    for itr in range(niter):\n",
    "        # ADMM approach\n",
    "        \n",
    "        # Compute SVD of S - X + W/rho\n",
    "        U, E, V = np.linalg.svd(X - S - W/rho, full_matrices=False)\n",
    "        \n",
    "        # Update L based on the soft thresholding of the singular values\n",
    "        L = (U * soft(E, 1/rho)) @ V\n",
    "\n",
    "        # Update S\n",
    "        S = soft(X - L - W/rho, lam/rho)\n",
    "        \n",
    "        # Update W\n",
    "        W = W + rho * (L + S - X)\n",
    "        \n",
    "        out.append(L)\n",
    "    return L, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the Data \n",
    "mnist_49_3000 = sio.loadmat('mnist_49_3000.mat')\n",
    "x = mnist_49_3000['x']\n",
    "y = mnist_49_3000['y']\n",
    "d, n = x.shape\n",
    "x = x - np.mean(x,axis=1,keepdims=True) #Centering the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of original data matrix is: 566\n",
      "Rank of low rank data matrix is: 286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e903a0b610>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD4CAYAAADmWv3KAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZXElEQVR4nO3de3Bc533e8e9vd7EAFneQyztpUjKliKIUSUEYKXJUjSnWtOSKaho31Iw7bKqUTaPUstsZVxplquYPdxQ348ZO6kxZ2QkbO1IVxbY4nqQSQ0mWE0cXSKJiUhRFihRJiCQAghdcSAAE+Osfe0AugQUvu1icPQfPZwazu2d3cR6J4IOX7zn7HnN3REQkfhJhBxARkfJQwYuIxJQKXkQkplTwIiIxpYIXEYmpVNgBAGbPnu1Lly4NO4aISKS89dZbx9w9O9nzFVHwS5cupb29PewYIiKRYmYHLvW8pmhERGJKBS8iElMqeBGRmFLBi4jElApeRCSmVPAiIjGlghcRialIF/yRU2f4+ou72dfdH3YUEZGKE+mC7+od4psv7eWjnoGwo4iIVJxIF3wyYQCMjOqiJSIi48Wi4EfPqeBFRMaLdMGnxgpelx0UEZkg0gWf0AheRGRSkS74lApeRGRSkS748wdZVfAiIhPEouA1ghcRmUgFLyISU5cteDP7jpl1mdmOvG3/3czeN7N/NLMfmFlz3nOPmdleM9ttZp8pU24AUolcfBW8iMhEVzKC/zNg7bhtW4GV7n4z8AHwGICZrQDWAzcG7/mWmSWnLO04SdMcvIjIZC5b8O7+KnB83LYX3X0kePgasCi4vw54xt2H3H0/sBdYNYV5L5JM5gr+nApeRGSCqZiD/zfA3wT3FwKH8p7rCLZNYGYbzazdzNq7u7uL2rFG8CIikyup4M3scWAE+N7YpgIvK9i+7r7J3dvcvS2bzRa1/7GDrOf0SVYRkQlSxb7RzDYAnwNWu59v2A5gcd7LFgGHi493aSktNiYiMqmiRvBmthb4z8D97n4676ktwHozqzazZcBy4I3SYxZ2YamCc+XahYhIZF12BG9mTwN3A7PNrAN4gtxZM9XAVsvNg7/m7r/l7jvN7FngPXJTNw+7+2i5wkNuFK/FxkREJrpswbv7gwU2f/sSr/8q8NVSQl2NRMJ0kFVEpIBIf5IVghG85uBFRCaIfMEnNUUjIlJQPApeUzQiIhNEvuBTKngRkYIiX/AawYuIFBb9gjedRSMiUkj0Cz5pWmxMRKSA6Be8RvAiIgVFv+A1By8iUlDkCz6VSKjgRUQKiHzBa6kCEZHCIl/wqYRpPXgRkQIiX/BJjeBFRAqKRcFrPXgRkYliUvAawYuIjBf9gjcVvIhIIZEv+FRSc/AiIoVEvuCTCS1VICJSSPQLXksViIgUFP2C10FWEZGCIl/wqaQKXkSkkMgXfEJn0YiIFHTZgjez75hZl5ntyNvWamZbzWxPcNuS99xjZrbXzHab2WfKFXxMShfdFhEp6EpG8H8GrB237VFgm7svB7YFjzGzFcB64MbgPd8ys+SUpS0gkTBGRlXwIiLjXbbg3f1V4Pi4zeuAzcH9zcADedufcfchd98P7AVWTU3UwnTRbRGRwoqdg5/r7kcAgts5wfaFwKG813UE2yYws41m1m5m7d3d3UXGgGQioSkaEZECpvogqxXYVrB93X2Tu7e5e1s2my16h8kEGsGLiBRQbMF3mtl8gOC2K9jeASzOe90i4HDx8S5PV3QSESms2ILfAmwI7m8Ans/bvt7Mqs1sGbAceKO0iJemDzqJiBSWutwLzOxp4G5gtpl1AE8ATwLPmtlDwEHg8wDuvtPMngXeA0aAh919tEzZgbELfmg9eBGR8S5b8O7+4CRPrZ7k9V8FvlpKqKuRW2xsuvYmIhIdkf8ka26xMTW8iMh40S/4hHHOwXWqpIjIRSJf8KlE7sxMHWgVEblY5As+ERS81oQXEblY5At+bAR/TlM0IiIXiXzBJzWCFxEpKD4FrxUlRUQuEvmC10FWEZHCIl/wyUTuP0EFLyJyscgXfOr8HLw+7CQiki/yBZ/UFI2ISEGRL/hUUmfRiIgUEvmC1wheRKSwyBd8KjjIqtMkRUQuFoOC1wheRKSQyBd8MqmzaERECol8wWsELyJSWOQLXmvRiIgUFvmCT+mTrCIiBUW+4DWCFxEpLPIFf2EOXgdZRUTyRb7gtVywiEhhJRW8mX3ZzHaa2Q4ze9rMasys1cy2mtme4LZlqsIWMrZUgebgRUQuVnTBm9lC4ItAm7uvBJLAeuBRYJu7Lwe2BY/LJqU5eBGRgkqdokkBtWaWAjLAYWAdsDl4fjPwQIn7uCStBy8iUljRBe/uHwN/ABwEjgCn3P1FYK67HwlecwSYU+j9ZrbRzNrNrL27u7vYGBrBi4hMopQpmhZyo/VlwAKgzsy+cKXvd/dN7t7m7m3ZbLbYGHmrSeosGhGRfKVM0dwD7Hf3bnc/C3wf+GWg08zmAwS3XaXHnJxG8CIihZVS8AeB280sY2YGrAZ2AVuADcFrNgDPlxbx0rQevIhIYali3+jur5vZc8DbwAjwDrAJqAeeNbOHyP0S+PxUBJ2M1oMXESms6IIHcPcngCfGbR4iN5qfFkmdBy8iUlDkP8laFRT88KgOsoqI5It8waeTCZIJ4/TwSNhRREQqSuQL3szIpJMMDI2GHUVEpKJEvuABMukkZ4ZV8CIi+WJR8HXpFAOaohERuUgsCr5WI3gRkQliUfAawYuITBSLgs9UawQvIjJePAo+naR/SCN4EZF8sSj4lkyak6fPhh1DRKSixKLgsw3V9AwMc1afZhUROS82BQ/Q0z8cchIRkcoRj4KvzxV8V99gyElERCpHLAq+tS4NoHl4EZE8sSj4hpoqAPoGdSaNiMiYWBR8Y21uWfveQY3gRUTGxKPggxF87xkVvIjImFgUfCadJJkwTdGIiOSJRcGbGQ01KU3RiIjkiUXBQ26aRlM0IiIXxKfga1P0aopGROS82BR8Q3UVfZqiERE5r6SCN7NmM3vOzN43s11mdoeZtZrZVjPbE9y2TFXYS2msTdF7RiN4EZExpY7gvwH8P3f/OeDngV3Ao8A2d18ObAsel11jTZUOsoqI5Cm64M2sEbgL+DaAuw+7+0lgHbA5eNlm4IHSIl6ZxtoqnSYpIpKnlBH8NUA38Kdm9o6ZPWVmdcBcdz8CENzOKfRmM9toZu1m1t7d3V1CjJyGmhT9QyOMaMlgERGgtIJPAbcBf+LutwIDXMV0jLtvcvc2d2/LZrMlxMgZ+zSrruwkIpJTSsF3AB3u/nrw+Dlyhd9pZvMBgtuu0iJemcZaLTgmIpKv6IJ396PAITO7Pti0GngP2AJsCLZtAJ4vKeEVaqzJLTh2Sh92EhEBctMspfgPwPfMLA3sA36D3C+NZ83sIeAg8PkS93FFxpYM1pk0IiI5JRW8u28H2go8tbqU71uMsSWDNUUjIpITm0+yjh1k1RSNiEhObAo+21BNwqDj+Omwo4iIVITYFHxNVZKls+v4oLM/7CgiIhUhNgUPsGxWHQc0ghcRAWJW8C11aa0JLyISiFXBN9dWcfL0cNgxREQqQrwKPlPFwPAowyNaj0ZEJFYF35RJAzpVUkQEYlbwzbVj58JrmkZEJF4Fn8kV/MnTGsGLiMSq4JuCEfwJFbyISLwKvrk2NwevM2lERGJW8E0ZrUcjIjImVgXfUJ0iYZqDFxGBmBV8ImG0ZNL0DGiKRkQkVgUPuVUlu/sGw44hIhK62BX83MYauvqGwo4hIhK62BX8nIZqOns1ghcRiV3BL27N0NU3RJ+uzSoiM1zsCv7mRU24w886ToUdRUQkVLEr+E/OqQfg0Ald+ENEZrbYFXxrXe7TrFquQERmupIL3sySZvaOmf0oeNxqZlvNbE9w21J6zCtXW5WkOpXghM6FF5EZbipG8I8Au/IePwpsc/flwLbg8bQxM1rr0hxXwYvIDFdSwZvZIuA+4Km8zeuAzcH9zcADpeyjGM2ZNCe04JiIzHCljuD/EPgKkH+NvLnufgQguJ1T6I1mttHM2s2svbu7u8QYF2utq9IcvIjMeEUXvJl9Duhy97eKeb+7b3L3Nndvy2azxcYoqCWT1hy8iMx4qRLeeydwv5ndC9QAjWb2XaDTzOa7+xEzmw90TUXQq9Fal+a4pmhEZIYregTv7o+5+yJ3XwqsB15y9y8AW4ANwcs2AM+XnPIqNWfSnDpzlpHRc5d/sYhITJXjPPgngTVmtgdYEzyeVq2ZKtx14Q8RmdlKmaI5z91fAV4J7vcAq6fi+xZrTmMNAEd7B5lVXx1mFBGR0MTuk6wAS1ozABw6ruUKRGTmimXBLw4K/kCPCl5EZq5YFnxTbRULm2t5++CJsKOIiIQmlgUPcNd1s/np3h7O6kwaEZmhYlvw/+S6LH1DI7x76GTYUUREQhHbgl+5sAmAPV39IScREQlHbAt+flMtqYRxUGfSiMgMFduCTyaMxa0Zdh/tCzuKiEgoYlvwAPfcMIdXP+imq28w7CgiItMu1gW/ftUSRs45W7YfDjuKiMi0i3XBX5ut59psHS+9P+0LWoqIhC7WBQ9w303z+emHPfys41TYUUREplXsC/5Xb1sEwK6jvSEnERGZXrEv+EUtudMlX9vXE3YUEZFpFfuCTyUT/PziZrZsP0zfoNaHF5GZI/YFD/Dbd1/LyDln1xGdEy8iM8eMKPibFzUD8OZHx8MNIiIyjWZEwWcbqrl5URNb3+sMO4qIyLSZEQUP8Jkb57H90En2avExEZkhZkzB/9ovLKK+OsW3Xt4bdhQRkWkxYwp+bmMNa1fO44fbP+Z9nRMvIjPAjCl4gEdWL+ecwws7NBcvIvFXdMGb2WIze9nMdpnZTjN7JNjeamZbzWxPcNsydXFLs7g1w8/Na+Af9h0LO4qISNmVMoIfAf6Tu98A3A48bGYrgEeBbe6+HNgWPK4Y9900n9f2Hecne7rDjiIiUlZFF7y7H3H3t4P7fcAuYCGwDtgcvGwz8ECJGafUQ7+yjFl1aZ5t7wg7iohIWU3JHLyZLQVuBV4H5rr7Ecj9EgDmTPKejWbWbmbt3d3TN5rOpFPcdV2WV3Z3cfjkmWnbr4jIdCu54M2sHvgr4EvufsWnp7j7Jndvc/e2bDZbaoyr8sXVy3GH+775E17XImQiElMlFbyZVZEr9++5+/eDzZ1mNj94fj5QcVfbWDa7jmc23k4mneK//c37uHvYkUREplwpZ9EY8G1gl7t/Pe+pLcCG4P4G4Pni45XPyoVN/Pu7r+XdQyd568CJsOOIiEy5UkbwdwL/Cvi0mW0Pvu4FngTWmNkeYE3wuCL981sXUlOV4AfvfBx2FBGRKZcq9o3u/neATfL06mK/73Sqq06xZsU8trx7mHW3LGTVstawI4mITJkZ9UnWQr50z3Ja69I8+L9fY8fHum6riMTHjC/4a7P1PP/wnWTSSX73hzsYPDsadiQRkSkx4wseoDmT5pHVy9l+6CT/dctOzo6eCzuSiEjJip6Dj5vf/JVr2H20j2fePETf0Ah/tP5WEonJDjGIiFQ+FXye3/8XN9NUW8VTf7efa2fX8eU115E7G1REJHpU8HkSCePx+27g+OlhvvnSXrZ3nOIbv34LLXXpsKOJiFw1zcGPY2Y8+as385W11/OTPd38y//1DzrwKiKRpIIvIJ1K8Nt3f5I/fvA29nT1s+Z//FgLk4lI5KjgL+Hem+bxjfW3cHLgLPf/8d/z3dcO6AwbEYkMFfwlmBnrblnI//13d7B0Vobf/eEO/u3/aefIKY3mRaTyqeCvwIoFjfzlb93BE/9sBT/d28NdX3uZ3/mLtzl6ajDsaCIik9JZNFfIzPiNO5dxzw1z2fzTj/jz1w7wyu5ufu0XFvHQp5axuDUTdkQRkYtYJayF3tbW5u3t7WHHuCoHegb42gu72bqzk0QC1v/iEtaunMetS5qpTiXDjiciM4CZveXubZM+r4Ivzf5jA/zRS3vYsv0wI+echpoUX/z0ctaunKdRvYiUlQp+mvQOnuW1D3v47usHefWD3DVmVy1r5dfbFnPvTfOpTWtULyJTSwU/zdyd94/28fLuLp598xAf9ZwmlTA+tXw2bZ9o4b6bF7B0VkZLIIhIyVTwIXJ3Xt9/nBd2HuVvd3XSceIM7jC7Ps0vLZvF/bcsYOXCJhY01ajwReSqqeAryKHjp/nxB928feAEW3d10jc4AsC8xho+e9M8Vi1t5ReXtTK7vjrkpCISBSr4CnVmeJT3jvTy3uFT/PiDbl794BjDwadkr5tbz62LW7h+XgNtS1u4cUETSS1dLCLjqOAjYmhklJ2He3l933Fe3t3Fvu5+jvUPA5BJJ7kmW8c1s+u5NlvPNdk6lrRmWNyaoSVTpekdkRlKBR9hR06d4Y39x3nn4En2HRtgX3c/H5/MzeOPac5U8clsrviXz61nUUstC5prWdKaoalW5S8SZyr4mBk8O8r+YwN0nDjDgZ4B9h0bYG9XPx929dMzMHzRa6tTCeY21jCvsYY5jdXMa6xh7rj7cxtrdAqnSERdruDLtlSBma0FvgEkgafc/cly7WsmqalKcsP8Rm6Y3zjhuZ7+IY72DtJx4gyHjp+mq2+Io6cG6ewdZMfHp/jbXZ0Mnp24GmZjTSr3i6CphjkNNcxtrGZeUw2z6qpprUszqz5Na12alkxaxwJEIqQsBW9mSeB/AmuADuBNM9vi7u+VY3+SM6u+mln11dy4oKng8+5O39AInacG6ewdorN3kKO9g3T15h4f7R3kw65jdPUNMXJu4r/szKCptoqWTJq66iR16RT11Snqxr7SSeqq87clz9+vr06RSV94nEknNX0kUmblGsGvAva6+z4AM3sGWAeo4ENkZjTWVNFYU8XyuQ2Tvu7cOadnYJiegSGO9w9zbGCY4/1DnDh9lhOnhzlx+iwDQyP0D41wtHcwuD/KwNAIZ67w6ldmUJdOnf9FoX8ZyEx19/VZHr9vRVm+d7kKfiFwKO9xB/BL+S8ws43ARoAlS5aUKYYUI5Ewsg3VZBuu/nz80XPO6eERBoZG6R8aYSD46h8aYWD4wi+C03m/FPqHR6iEY0EiYZjbWFO2712ugi80HLvob7C7bwI2Qe4ga5lyyDRLJoyGmioaaqrCjiIy45Xrgh8dwOK8x4uAw2Xal4iIFFCugn8TWG5my8wsDawHtpRpXyIiUkBZpmjcfcTMfgd4gdxpkt9x953l2JeIiBRWtvPg3f2vgb8u1/cXEZFL00W3RURiSgUvIhJTKngRkZhSwYuIxFRFrCZpZt3AgRK+xWzg2BTFmUqVmguUrVjKVhxlK87lsn3C3bOTPVkRBV8qM2u/1JKZYanUXKBsxVK24ihbcUrNpikaEZGYUsGLiMRUXAp+U9gBJlGpuUDZiqVsxVG24pSULRZz8CIiMlFcRvAiIjKOCl5EJKYiXfBmttbMdpvZXjN7NIT9f8fMusxsR962VjPbamZ7gtuWvOceC7LuNrPPlDHXYjN72cx2mdlOM3ukgrLVmNkbZvZukO33KiVb3v6SZvaOmf2okrKZ2Udm9jMz225m7RWWrdnMnjOz94OfuzsqIZuZXR/8/xr76jWzL1VCtmBfXw7+Huwws6eDvx9Tl83dI/lFbhniD4FrgDTwLrBimjPcBdwG7Mjb9jXg0eD+o8DvB/dXBBmrgWVB9mSZcs0HbgvuNwAfBPuvhGwG1Af3q4DXgdsrIVtexv8I/AXwo0r5Mw329xEwe9y2Ssm2GfjN4H4aaK6UbHkZk8BR4BOVkI3cpU33A7XB42eBfz2V2cr6P7TMf1h3AC/kPX4MeCyEHEu5uOB3A/OD+/OB3YXykVsr/45pyvg8sKbSsgEZ4G1y1+utiGzkrj62Dfg0Fwq+UrJ9xMSCDz0b0BgUlVVatnF5/inw95WSjQvXrm4lt3T7j4KMU5YtylM0hS7svTCkLPnmuvsRgOB2TrA9lLxmthS4ldxIuSKyBVMg24EuYKu7V0w24A+BrwDn8rZVSjYHXjSztyx30fpKyXYN0A38aTC19ZSZ1VVItnzrgaeD+6Fnc/ePgT8ADgJHgFPu/uJUZotywV/2wt4VZtrzmlk98FfAl9y991IvLbCtbNncfdTdbyE3Wl5lZisv8fJpy2ZmnwO63P2tK31LgW3l/DO9091vAz4LPGxmd13itdOZLUVuqvJP3P1WYIDc1MJkwvi7kAbuB/7yci8tsK1cP28twDpy0y0LgDoz+8JUZotywVfqhb07zWw+QHDbFWyf1rxmVkWu3L/n7t+vpGxj3P0k8AqwtkKy3Qncb2YfAc8Anzaz71ZINtz9cHDbBfwAWFUh2TqAjuBfYgDPkSv8Ssg25rPA2+7eGTyuhGz3APvdvdvdzwLfB355KrNFueAr9cLeW4ANwf0N5Oa/x7avN7NqM1sGLAfeKEcAMzPg28Aud/96hWXLmllzcL+W3A/5+5WQzd0fc/dF7r6U3M/TS+7+hUrIZmZ1ZtYwdp/cXO2OSsjm7keBQ2Z2fbBpNfBeJWTL8yAXpmfGMoSd7SBwu5llgr+zq4FdU5qt3Ac2ynzQ5F5yZ4h8CDwewv6fJjd3dpbcb9eHgFnkDtLtCW5b817/eJB1N/DZMub6FLl/uv0jsD34urdCst0MvBNk2wH8l2B76NnG5bybCwdZQ89Gbp773eBr59jPeyVkC/Z1C9Ae/Ln+EGipoGwZoAdoyttWKdl+j9wAZwfw5+TOkJmybFqqQEQkpqI8RSMiIpegghcRiSkVvIhITKngRURiSgUvIhJTKngRkZhSwYuIxNT/B/aEZH8K0SU7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Rho = 1 \n",
    "ld = 1/np.sqrt(np.amax(x.shape))\n",
    "\n",
    "x_hat, out_admm =  ADMM(L=x, S=np.zeros(x.shape),X=x, lam=ld, rho = Rho)\n",
    "\n",
    "print(\"Rank of original data matrix is: {}\".format(np.linalg.matrix_rank(x)))\n",
    "print(\"Rank of low rank data matrix is: {}\".format(np.linalg.matrix_rank(x_hat)))\n",
    "U,S,V = np.linalg.svd(x_hat, full_matrices=False)\n",
    "plt.plot(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project low rank data matrix (x_hat) to top k left singular vectors of x_hat\n",
    "k = 50\n",
    "# Selecting k largest singular values\n",
    "S_proj = np.zeros(S.shape)\n",
    "S_proj[:k] = S[:k]\n",
    "# Projecting the matrix\n",
    "x_rpca = U * S_proj @ V\n",
    "\n",
    "ntr = 2000  # number of training points\n",
    "nts = n - 2000  # number of testing points\n",
    "\n",
    "x_tilde = np.concatenate([np.ones([1, n]), x_rpca], axis=0)  # append vector of 1 for the bias term\n",
    "\n",
    "# Split data into training/testing set\n",
    "xtr = x_tilde[:, :ntr]\n",
    "xts = x_tilde[:, ntr:]\n",
    "ytr = y[:, :ntr]\n",
    "yts = y[:, ntr:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularized logistic regression on the low rank matrix obtained above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "\n",
    "# Define sigmoid function\n",
    "def sigmoid_func(t):\n",
    "    return 1. / (1 + np.exp(-t))\n",
    "\n",
    "\n",
    "# Define derivative of sigmoid function\n",
    "def sigmoid_func_derive(t):\n",
    "    return np.exp(-t) / np.square(1 + np.exp(-t))\n",
    "\n",
    "\n",
    "# Phi (defined in problem 3(a))\n",
    "def phi(t):\n",
    "    return np.log(1 + np.exp(-t))\n",
    "\n",
    "\n",
    "\n",
    "def obj_func(xtr, ytr, lam, theta):\n",
    "    \n",
    "    obj_val = np.sum(phi(xtr.T.dot(theta) * ytr.T)) + lam * np.square(np.linalg.norm(theta))\n",
    "    return obj_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of Gradient Descent\n",
    "def GD(x, gf, eta, fun=lambda x,itr: 0, niter=100, eps=1e-5):    \n",
    "    '''\n",
    "    Input: \n",
    "        x:     intilalization \n",
    "        gf:    gradient function takes position argument \n",
    "        eta:   step size\n",
    "        fun:   objective value takes position argument \n",
    "        niter: number of iterations \n",
    "        eps:   tolerance for termination criteria \n",
    "\n",
    "    Itermediate: \n",
    "        grad:  gradient\n",
    "\n",
    "    Output: \n",
    "        x:     final solution \n",
    "        itr:   numer of iteration \n",
    "        out:   objective values per iterations \n",
    "    '''\n",
    "    out=np.empty(niter+1)\n",
    "    out[0] = fun(x,0)\n",
    "    for itr in range(niter):\n",
    "        '''\n",
    "        Gradient Descent\n",
    "        '''\n",
    "        x -= eta * gf(x)\n",
    "        out[itr+1] = fun(x,itr+1)\n",
    "        if (np.abs(out[itr+1] - out[itr])/np.abs(out[itr])  < eps):\n",
    "            return x, itr, out[:itr+1]\n",
    "        itr += 1\n",
    "    \n",
    "    out[: itr+1] = fun(x,itr+1)\n",
    "    return x, itr, out[:itr+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error of the logistic regression classifier is 4.9\n",
      "Number of iterations needed: 437\n"
     ]
    }
   ],
   "source": [
    "# Initialize with the zero vector. +1 for the bias term\n",
    "lam = 10.0\n",
    "eps = 1e-5\n",
    "Niter = 2000 #maximum number of iterations\n",
    "\n",
    "# Compute the step size\n",
    "_sum = 0\n",
    "for i in range(ntr):\n",
    "    _sum += np.dot(xtr[:,i], xtr[:,i])\n",
    "\n",
    "L = 2*lam + 0.25*_sum # (2*lambda + 0.25 * sum of )\n",
    "step_size = 2/(L + 2*lam)\n",
    "\n",
    "# Gradient function\n",
    "\n",
    "def grad(z):\n",
    "    gf = np.zeros([d+1,1])\n",
    "    gf[:,0] = ( 2 * lam ) * z[:,0]\n",
    "    for i in range(ntr):\n",
    "        gf[:,0] -= xtr[:,i] * ytr[:,i][0] / ( 1 + np.exp( ytr[:,i][0] * np.dot(z[:,0], xtr[:,i])))\n",
    "    return gf\n",
    "                \n",
    "\n",
    "#grad = lambda z: ( 2 * lam / ntr ) * z  -  xtr[:,i] * ytr[:,i] / ( 1 + np.exp( ytr[:,i] * np.dot(z[:,0], xtr[:,i]) )\n",
    "\n",
    "obj = lambda z,itr: obj_func(xtr,ytr,lam, z)\n",
    "\n",
    "theta, niter, out = GD(np.zeros([d+1,1]), grad, step_size, obj, Niter,eps)\n",
    "\n",
    "# Logistic regression estimate\n",
    "y_pred = np.ones([yts.shape[1], 1]) * -1\n",
    "y_pred[xts.T.dot(theta) >= 0] = 1\n",
    "test_error = np.sum(y_pred.T != yts) * 100. / float(nts)\n",
    "\n",
    "print(\"The test error of the logistic regression classifier is {}\".format(test_error))\n",
    "print(\"Number of iterations needed: {}\".format(niter))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
